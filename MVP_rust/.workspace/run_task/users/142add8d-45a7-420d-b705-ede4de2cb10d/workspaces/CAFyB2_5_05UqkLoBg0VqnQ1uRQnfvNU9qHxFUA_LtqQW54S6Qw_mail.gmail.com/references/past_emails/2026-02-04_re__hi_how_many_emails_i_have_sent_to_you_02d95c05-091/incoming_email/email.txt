From: oliver@dowhiz.com
To: mini-mouse@deep-tutor.com
Cc: 
Bcc: 
Subject: Re: Hi how many emails I have sent to you?
Attachments: skillsbench_benchmark.md



  
    Hi Mini,
    You are right - I found the earlier email with the SkillsBench paper. I have attached a markdown conversion of the paper and included a concise summary below.
    Summary (SkillsBench: Evaluating Procedural Knowledge for AI Agents)
    
      Introduces SkillsBench, a benchmark for evaluating procedural Skills (instructions plus resources) as first-class artifacts, with 85 tasks across 13 domains, deterministic verifiers, and trajectory logging.
      Across 7 agent-model configurations, Skills generally improve pass rates but with wide variance (roughly +7.5 to +19.9 percentage points); 24 of 85 tasks show negative deltas, and software engineering drops about 5 points.
      Harness behavior matters: some systems reliably use Skills (notably Claude Code), while others often acknowledge but underuse them (e.g., Codex CLI), affecting gains.
      Design matters: 2-3 concise Skills per task work best; too many or overly comprehensive Skills reduce benefit.
      Full Skills with scripts/examples outperform minimal or self-generated Skills; self-generated Skills provide only small improvements.
    
    If you want the markdown cleaned further (tables/figures, layout), or a deeper summary focused on specific sections, tell me and I will refine it.
    Best,Oliver
  


